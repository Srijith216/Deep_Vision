{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepVision_task",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srijith216/Deep_Vision/blob/main/DeepVision_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVC3OYSK8v9z",
        "outputId": "c66f7a71-9298-4596-80df-ea6e496ed2b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "z-Xq0h7f8xX6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DeepVision/arxiv_data.csv')"
      ],
      "metadata": {
        "id": "BCs4GMnO87sD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jlmaCqI9GlI",
        "outputId": "671f958d-e7f2-47f8-abf8-d59f81c452e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51774, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CfF5onlm9e4J",
        "outputId": "4cca4aad-d297-4a69-b8fe-77fbe1c8eb2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  titles  \\\n",
              "943    Camera-trap images segmentation using multi-la...   \n",
              "44626  Mining Spatio-temporal Data on Industrializati...   \n",
              "37346  From Known to Unknown: Knowledge-guided Transf...   \n",
              "51723  Molecular Structure Extraction From Documents ...   \n",
              "28940  PointHop: An Explainable Machine Learning Meth...   \n",
              "\n",
              "                                               summaries  \\\n",
              "943    The segmentation of animals from camera-trap i...   \n",
              "44626  Despite the growing availability of big data i...   \n",
              "37346  Time series forecasting (TSF) is fundamentally...   \n",
              "51723  Chemical structure extraction from documents r...   \n",
              "28940  An explainable machine learning method for poi...   \n",
              "\n",
              "                              terms  \n",
              "943                       ['cs.CV']  \n",
              "44626            ['cs.CV', 'cs.IR']  \n",
              "37346                     ['cs.LG']  \n",
              "51723  ['cs.LG', 'physics.chem-ph']  \n",
              "28940            ['cs.CV', 'cs.LG']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb633892-11de-4ce8-9378-c817593b414a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>Camera-trap images segmentation using multi-la...</td>\n",
              "      <td>The segmentation of animals from camera-trap i...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44626</th>\n",
              "      <td>Mining Spatio-temporal Data on Industrializati...</td>\n",
              "      <td>Despite the growing availability of big data i...</td>\n",
              "      <td>['cs.CV', 'cs.IR']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37346</th>\n",
              "      <td>From Known to Unknown: Knowledge-guided Transf...</td>\n",
              "      <td>Time series forecasting (TSF) is fundamentally...</td>\n",
              "      <td>['cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51723</th>\n",
              "      <td>Molecular Structure Extraction From Documents ...</td>\n",
              "      <td>Chemical structure extraction from documents r...</td>\n",
              "      <td>['cs.LG', 'physics.chem-ph']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28940</th>\n",
              "      <td>PointHop: An Explainable Machine Learning Meth...</td>\n",
              "      <td>An explainable machine learning method for poi...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb633892-11de-4ce8-9378-c817593b414a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb633892-11de-4ce8-9378-c817593b414a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb633892-11de-4ce8-9378-c817593b414a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download(['punkt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS6YhixUDxKA",
        "outputId": "d815651f-e20c-4b09-c5ef-67738fcb1f9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.DataFrame()\n",
        "train_set['titles'] = data['titles'][:10000]"
      ],
      "metadata": {
        "id": "_IETMoK39OBz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zpXRRgZNHrZK",
        "outputId": "7ff22b0e-dfd7-486b-a76a-597aab40774a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...\n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...\n",
              "2  Enforcing Mutual Consistency of Hard Regions f...\n",
              "3  Parameter Decoupling Strategy for Semi-supervi...\n",
              "4  Background-Foreground Segmentation for Interio..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d608aa76-808d-4743-b570-e2ccc11a4daf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d608aa76-808d-4743-b570-e2ccc11a4daf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d608aa76-808d-4743-b570-e2ccc11a4daf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d608aa76-808d-4743-b570-e2ccc11a4daf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = []\n",
        "for abstract in train_set['titles']:\n",
        "  abstract = re.sub(r'[^a-zA-Z]', r' ',abstract)\n",
        "  abstract = re.sub(r' +', r' ',abstract)\n",
        "  abstract = abstract.strip().lower()\n",
        "  clean_text.append(abstract)"
      ],
      "metadata": {
        "id": "aEJ8PTFd9bRr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['clean_text'] = clean_text\n",
        "train_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vx8OYE7YIPQ_",
        "outputId": "91feb33a-c06e-422d-bee2-761682152f73"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                          clean_text  \n",
              "0  survey on semantic stereo matching semantic de...  \n",
              "1  future ai guiding principles and consensus rec...  \n",
              "2  enforcing mutual consistency of hard regions f...  \n",
              "3  parameter decoupling strategy for semi supervi...  \n",
              "4  background foreground segmentation for interio...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24a69c3e-d1c0-44fd-a944-ad7fb5284519\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>survey on semantic stereo matching semantic de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>future ai guiding principles and consensus rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>enforcing mutual consistency of hard regions f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>parameter decoupling strategy for semi supervi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>background foreground segmentation for interio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24a69c3e-d1c0-44fd-a944-ad7fb5284519')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24a69c3e-d1c0-44fd-a944-ad7fb5284519 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24a69c3e-d1c0-44fd-a944-ad7fb5284519');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "FOI0IRMdDYU5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_set['clean_text'])\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "MlNYXTY1FE5b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total words: {total_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1UrGYwsFVUx",
        "outputId": "4a6e5b10-1937-46be-b7b4-30d46a870dc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 7868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in train_set['clean_text']:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    \n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "print(\"Total input sequences: \", len(input_sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNoDt-89GGxO",
        "outputId": "54bb7cee-936e-4459-b03b-6d0674111963"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total input sequences:  86900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_len, padding='pre'))"
      ],
      "metadata": {
        "id": "ERXXMPOBIlc1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(label,num_classes = total_words)"
      ],
      "metadata": {
        "id": "iSPkrKF6I3LR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_len-1))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO5cgvHrJNfC",
        "outputId": "1e3fa397-ccb0-4d42-a6cb-b0a6e7d76f2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 31, 100)           786800    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 300)              301200    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7868)              2368268   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,456,268\n",
            "Trainable params: 3,456,268\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNUtCRgoKRKl",
        "outputId": "df41ef61-ed52-451e-e9a6-d6910fadf188"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2716/2716 [==============================] - 37s 10ms/step - loss: 5.8843 - accuracy: 0.1383\n",
            "Epoch 2/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 4.9553 - accuracy: 0.2231\n",
            "Epoch 3/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 4.4914 - accuracy: 0.2554\n",
            "Epoch 4/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 4.1222 - accuracy: 0.2828\n",
            "Epoch 5/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 3.7920 - accuracy: 0.3101\n",
            "Epoch 6/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 3.4885 - accuracy: 0.3401\n",
            "Epoch 7/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 3.2114 - accuracy: 0.3762\n",
            "Epoch 8/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 2.9578 - accuracy: 0.4127\n",
            "Epoch 9/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 2.7280 - accuracy: 0.4466\n",
            "Epoch 10/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 2.5203 - accuracy: 0.4826\n",
            "Epoch 11/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 2.3322 - accuracy: 0.5151\n",
            "Epoch 12/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 2.1603 - accuracy: 0.5466\n",
            "Epoch 13/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 2.0079 - accuracy: 0.5742\n",
            "Epoch 14/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.8675 - accuracy: 0.6005\n",
            "Epoch 15/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 1.7411 - accuracy: 0.6273\n",
            "Epoch 16/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.6261 - accuracy: 0.6500\n",
            "Epoch 17/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.5220 - accuracy: 0.6693\n",
            "Epoch 18/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.4288 - accuracy: 0.6889\n",
            "Epoch 19/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.3424 - accuracy: 0.7055\n",
            "Epoch 20/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.2624 - accuracy: 0.7244\n",
            "Epoch 21/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.1922 - accuracy: 0.7375\n",
            "Epoch 22/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.1279 - accuracy: 0.7512\n",
            "Epoch 23/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.0688 - accuracy: 0.7635\n",
            "Epoch 24/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 1.0145 - accuracy: 0.7747\n",
            "Epoch 25/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.9653 - accuracy: 0.7849\n",
            "Epoch 26/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.9205 - accuracy: 0.7939\n",
            "Epoch 27/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.8785 - accuracy: 0.8037\n",
            "Epoch 28/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.8416 - accuracy: 0.8098\n",
            "Epoch 29/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.8066 - accuracy: 0.8177\n",
            "Epoch 30/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.7769 - accuracy: 0.8236\n",
            "Epoch 31/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.7480 - accuracy: 0.8301\n",
            "Epoch 32/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.7237 - accuracy: 0.8340\n",
            "Epoch 33/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.6991 - accuracy: 0.8394\n",
            "Epoch 34/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.6765 - accuracy: 0.8448\n",
            "Epoch 35/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.6557 - accuracy: 0.8487\n",
            "Epoch 36/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.6396 - accuracy: 0.8519\n",
            "Epoch 37/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.6214 - accuracy: 0.8559\n",
            "Epoch 38/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.6083 - accuracy: 0.8572\n",
            "Epoch 39/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5969 - accuracy: 0.8592\n",
            "Epoch 40/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5855 - accuracy: 0.8613\n",
            "Epoch 41/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5722 - accuracy: 0.8645\n",
            "Epoch 42/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5584 - accuracy: 0.8661\n",
            "Epoch 43/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5521 - accuracy: 0.8679\n",
            "Epoch 44/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5458 - accuracy: 0.8678\n",
            "Epoch 45/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5338 - accuracy: 0.8717\n",
            "Epoch 46/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5268 - accuracy: 0.8717\n",
            "Epoch 47/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5196 - accuracy: 0.8730\n",
            "Epoch 48/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5143 - accuracy: 0.8741\n",
            "Epoch 49/50\n",
            "2716/2716 [==============================] - 28s 10ms/step - loss: 0.5126 - accuracy: 0.8729\n",
            "Epoch 50/50\n",
            "2716/2716 [==============================] - 27s 10ms/step - loss: 0.5037 - accuracy: 0.8758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictNextN(word,n):\n",
        "  seed_text = word\n",
        "  for _ in range(n):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
        "    pred_x = model.predict(token_list)\n",
        "    predicted = np.argmax(pred_x,axis = 1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "  return seed_text"
      ],
      "metadata": {
        "id": "pDd2xIFcQN4R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictWithMiddle(word,n):\n",
        "  seed_text = word\n",
        "  for _ in range(n):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
        "    pred_x = model.predict(token_list)\n",
        "    predicted = np.argmax(pred_x,axis = 1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "    seed_list = seed_text.split()\n",
        "    seed_list = seed_list[::-1]\n",
        "    seed_text = ' '.join(seed_list)\n",
        "  return seed_text"
      ],
      "metadata": {
        "id": "d1LCBUL5QpVE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictPrevN(word,n):\n",
        "  og_word = word\n",
        "  seed_text = word\n",
        "  for _ in range(n):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
        "    pred_x = model.predict(token_list)\n",
        "    predicted = np.argmax(pred_x,axis = 1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "    seed_list = seed_text.split()\n",
        "    seed_list = seed_list[::-1]\n",
        "    seed_list.remove(og_word)\n",
        "    seed_text = ' '.join(seed_list)\n",
        "    seed_text += \" \" + og_word\n",
        "  return seed_text"
      ],
      "metadata": {
        "id": "-88mTtQhWYsc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictNextN(\"attention\",10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r8bOnFztO6bj",
        "outputId": "c04ef29d-574c-4a97-81de-bc9a60b251a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'attention aware generative adversarial networks ata gans gans for self supervised'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictWithMiddle(\"attention\",10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_5FxLMlpTJM1",
        "outputId": "1abc4c72-e2d3-4267-8737-02f7490cbb88"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'manifolds on learning representation based attention aware domain adaptation for bayesian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictPrevN(\"attention\",10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2h742wBCWp32",
        "outputId": "c29417db-b390-44e8-b4c8-5f6c6ce45010"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'based based design efficient based aware for efficient neural model attention'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "oFsUK6Yvfjrx",
        "outputId": "489cdf06-9fe2-47ba-999a-047cc2a91d56"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ec3e5aa-f587-46b8-8f59-f79defbac7f1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ec3e5aa-f587-46b8-8f59-f79defbac7f1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving inputs.txt to inputs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = open(\"inputs.txt\").read().split()\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPUkcv3SgQGh",
        "outputId": "9a0cfb7a-63cf-447c-e2c3-5d13fc2e6b9d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['space',\n",
              " 'medical',\n",
              " 'network',\n",
              " 'segmentation',\n",
              " 'mri',\n",
              " 'neural',\n",
              " 'survey',\n",
              " 'speech',\n",
              " 'mutual',\n",
              " 'segmentation']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inp in inputs:\n",
        "  print(f\"Word:{inp}\")\n",
        "  print(predictNextN(inp,10))\n",
        "  print(predictWithMiddle(inp,10))\n",
        "  print(predictPrevN(inp,10))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnv7278qgcbx",
        "outputId": "065f92b4-084b-4f2d-d997-765f56036a8a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word:space\n",
            "space time neural irradiance fields for free viewpoint video object detection\n",
            "visual for representations modal multi space time series with geometry embedding\n",
            "on evaluation estimation object multi time fusion perception for estimation space\n",
            "\n",
            "Word:medical\n",
            "medical image segmentation based on multi modal convolutional neural network study\n",
            "depth improve to classification image medical image synthesis using active learning\n",
            "synthesis synthesis translation data image image image image representation against medical\n",
            "\n",
            "Word:network\n",
            "network agnostic knowledge transfer for medical image segmentation a survey and\n",
            "training contrastive via learning representation network agnostic perceptual similarity for brain\n",
            "in design selection for representation agnostic representation pruning via augmentation network\n",
            "\n",
            "Word:segmentation\n",
            "segmentation of microscopy data for finding nuclei in divergent images using\n",
            "and images microscopy improve to segmentation of medical images using plant\n",
            "for via and the to of robust by using network segmentation\n",
            "\n",
            "Word:mri\n",
            "mri segmentation with multi relational semantic denoising via graph neural model\n",
            "tasks process gaussian for wear mri segmentation using convolutional networks cnns\n",
            "analysis with processing against wear segmentation segmentation on data with mri\n",
            "\n",
            "Word:neural\n",
            "neural architecture search using deep neural networks and monte carlo tree\n",
            "feature wise structured via network neural architecture search for object detection\n",
            "networks network object architecture network architecture network and prediction network neural\n",
            "\n",
            "Word:survey\n",
            "survey on emotional body gesture recognition using convolutional neural networks and\n",
            "techniques d in representations of survey on the web of dataset\n",
            "for for via image of on image via of d survey\n",
            "\n",
            "Word:speech\n",
            "speech image semantic alignment does not depend on any prior classification\n",
            "image to text in reasoning speech image domain normalization and data\n",
            "labels from diffusion to reasoning image representation to concepts embeddings speech\n",
            "\n",
            "Word:mutual\n",
            "mutual information gradient estimation for representation learning and learning disentangled object\n",
            "models constraints knowledge of modeling mutual information transfer learning for binary\n",
            "prediction representations representations context modeling information context annotations level uncertainty mutual\n",
            "\n",
            "Word:segmentation\n",
            "segmentation of microscopy data for finding nuclei in divergent images using\n",
            "and images microscopy improve to segmentation of medical images using plant\n",
            "for via and the to of robust by using network segmentation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "BVadhx_jJqZF"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}